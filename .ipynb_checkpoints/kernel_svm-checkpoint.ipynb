{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 1: Encoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, \n",
    "               input_size = 1,\n",
    "               embedding_size = 128,\n",
    "               hidden_size = 256,\n",
    "               n_layers = 4,\n",
    "               dropout = 0.5):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.linear = nn.Linear(input_size, embedding_size, n_layers)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, n_layers, \n",
    "                        dropout = dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: input batch data, \n",
    "        size of x: [sequence len, batch size, feature size]\n",
    "        \"\"\"\n",
    "\n",
    "        # size of embedded : [sequence len, batch size, embedding size]\n",
    "        embedded = self.dropout(F.relu(self.linear(x)))\n",
    "\n",
    "        output, (hidden, cell) = self.rnn(embedded)\n",
    "        # hidden: the last step hidden of each layer of rnn\n",
    "        # size of hidden : [num of layers * num directions, batch size, hidden size]\n",
    "        # num of directions is 1, since we are useing signle directional rnn\n",
    "        # cell: the last step cell of each layer of rnn\n",
    "        # size of cell: [num of layers * num of directions, batch size, hidden size]\n",
    "        \n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 2: Decoder\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                output_size = 1,\n",
    "                embedding_size = 128,\n",
    "                hidden_size = 256,\n",
    "                n_layers = 4,\n",
    "                dropout = 0.5):\n",
    "        super().__init__()\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Linear(output_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, n_layers, dropout = dropout)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        \"\"\"\n",
    "        x: input batch data, \n",
    "        size of x: [batch size, feature size]\n",
    "        x is only 2-dimensional, since the input is batches of last coordinate of the sequence,\n",
    "        so the sequence length has been removed\n",
    "        \"\"\"\n",
    "\n",
    "        # add a sequence dimension to the front of x, to allow for use of nn.LSTM method\n",
    "        x = x.unsqueeze(0)\n",
    "        # size(x) now becomes [1, batch size, feature size]\n",
    "        embedded = self.dropout(F.relu(self.embedding(x)))\n",
    "\n",
    "        # size of output : [seq len, batch size, hidden dimension * num of directions]\n",
    "        # size of hidden : [num of layers * num of directions, batch size, hidden dim]\n",
    "        # size of cell : [num of layers * num of directions, batch size, hidden dim]\n",
    "\n",
    "        # notice that sequence len and num of directions will always be 1 in the Decoder, therfore:\n",
    "        # size of output : [1, batch size, hidden dimension]\n",
    "        # size of hidden : [num of layers, batch size, hidden dim]\n",
    "        # size of cell : [num of directions, batch size, hidden dim]\n",
    "\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "\n",
    "        # prediction = [batch size, output size]\n",
    "        prediction = self.linear(output.squeeze(0))\n",
    "\n",
    "        return prediction, hidden, cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 3: Seq2seq\n",
    "class Seq2seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        #self.device = device\n",
    "\n",
    "        assert encoder.hidden_size == decoder.hidden_size, \\\n",
    "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "            \"Encoder and decoder must have equal number of layers!\"\n",
    "\n",
    "    def forward(self, x, y, teacher_forcing_ratio = 0.5):\n",
    "        \"\"\"\n",
    "        size of x : [observed sequence len, batch size, feature size]\n",
    "        size of y : [target sequence len, batch size, feature size]\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[1]\n",
    "        target_len = y.shape[0]\n",
    "        \n",
    "        # tensor to store decoder outputs of each time step\n",
    "        outputs = torch.zeros(y.shape)\n",
    "        \n",
    "        # last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "        hidden, cell = self.encoder(x)\n",
    "\n",
    "        # first input to decoder is last coordinates of x\n",
    "        decoder_input = x[-1, :, :]\n",
    "        \n",
    "        for i in range(target_len):\n",
    "            # run decode for one time step\n",
    "            output, hidden, cell = self.decoder(decoder_input, hidden, cell)\n",
    "            \n",
    "            # place predictions in a tensor holding predictions for each time step\n",
    "            outputs[i] = output\n",
    "\n",
    "            # decide if we are going to use teacher forcing or not\n",
    "            teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "\n",
    "            # output is the same shape as input, [batch_size, feature size]\n",
    "            # use output directly as input or use true lable depending on\n",
    "            # teacher_forcing is true or not\n",
    "            decoder_input = y[i] if teacher_forcing else output\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 4: RBF\n",
    "class RBF(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RBF, self).__init__()\n",
    "        self.sigma = nn.Parameter(torch.Tensor(1))\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        nn.init.constant_(self.sigma, 1)\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        '''\n",
    "        size of x1/x2 : [input sequence len, batch size, feature size],\n",
    "        for our task, the last two sizes are both 1.\n",
    "        '''\n",
    "        \n",
    "        value = (x1 - x2).pow(2).sum(0).pow(0.5) / self.sigma\n",
    "        \n",
    "        return torch.exp(-value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 5: Kernel\n",
    "# class Kernel refers to the structure combining Seq2seq module and RBF module.\n",
    "class Kernel(nn.Module):\n",
    "    def __init__(self, seq2seq, rbf, target_length, output_dim):\n",
    "        super().__init__()\n",
    "        # target_length: seq2seq2 output sequence length\n",
    "        self.target_length = target_length\n",
    "        # output_dim: seq2seq2 output embedding size; in our case being 1\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.seq2seq = seq2seq\n",
    "        self.rbf = rbf\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        \"\"\"\n",
    "        size of x1/x2 : [observed sequence len, batch size, feature size]\n",
    "        \"\"\"\n",
    "        # size of output_size corresponds to the size of seq2seq output\n",
    "        output_size = torch.randn(self.target_length, 1, self.output_dim)\n",
    "        \n",
    "        outputs1 = self.seq2seq(x1, output_size)\n",
    "        outputs2 = self.seq2seq(x2, output_size)\n",
    "        \n",
    "        # size of value : [batch size, feature size], both being 1 in our case\n",
    "        value = self.rbf(outputs1, outputs2)\n",
    "        \n",
    "        return value\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 6: Model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, kernel, xs, ys):\n",
    "        super().__init__()\n",
    "        # xs is a list of input data x,\n",
    "        # where the size of x is: [sequence len, batch size, feature size]\n",
    "        self.xs = xs\n",
    "        # ys is a list of label y.\n",
    "        # size of y: [batch size]\n",
    "        self.ys = ys\n",
    "        # data_length: num of items\n",
    "        self.data_length = len(ys)\n",
    "        # size of alphas: [num of items, batch size]\n",
    "        self.alphas = torch.randn(self.data_length, 1)\n",
    "        self.kernel = kernel\n",
    "        self.kernel_np = lambda x1, x2: kernel(x1, x2).detach().numpy()\n",
    "        \n",
    "    def forward(self):\n",
    "        \n",
    "        value = torch.zeros(1,1)\n",
    "        \n",
    "        for i in range(self.data_length):\n",
    "            for j in range(self.data_length):\n",
    "                # the i-j term of dual kernal-svm objective\n",
    "                term = self.alphas[i]*self.alphas[j]*self.ys[i]*self.ys[j]*self.kernel(self.xs[i],self.xs[j])  \n",
    "                value = torch.add(value, term)\n",
    "        \n",
    "        value = -0.5*value\n",
    "        \n",
    "        return value\n",
    "    \n",
    "    def update_alpha(self, alphas):\n",
    "        self.alphas = alphas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "devivce= cpu\n",
      "Model(\n",
      "  (kernel): Kernel(\n",
      "    (seq2seq): Seq2seq(\n",
      "      (encoder): Encoder(\n",
      "        (linear): Linear(in_features=1, out_features=128, bias=True)\n",
      "        (rnn): LSTM(128, 256, num_layers=4, dropout=0.5)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (decoder): Decoder(\n",
      "        (embedding): Linear(in_features=1, out_features=128, bias=True)\n",
      "        (rnn): LSTM(128, 256, num_layers=4, dropout=0.5)\n",
      "        (linear): Linear(in_features=256, out_features=1, bias=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (rbf): RBF()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# block 7, initialize the model\n",
    "\n",
    "INPUT_DIM = 1\n",
    "OUTPUT_DIM = 1\n",
    "ENC_EMB_DIM = 128\n",
    "DEC_EMB_DIM = 128\n",
    "HID_DIM = 256\n",
    "N_LAYERS = 4\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "TARG_LENGTH = 13\n",
    "\n",
    "dev = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"devivce=\", dev)\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "seq = Seq2seq(enc, dec)\n",
    "rbf = RBF()\n",
    "kernel = Kernel(seq, rbf, TARG_LENGTH, OUTPUT_DIM)\n",
    "\n",
    "# WARNING ------------ interface with wzy --------------------------------------------------------------- \n",
    "# this is the interface to incorporate traing datasets into the model\n",
    "# X_train should be a list of input data x,\n",
    "# where x should be a torch.tensor, size: [sequence len, batch size, feature size]\n",
    "# Y_train should be a list of label y.\n",
    "# where y should be a torch.tensor, size: [batch size]\n",
    "# in our case: batch size and feature size are both set to 1\n",
    "# refer to block 6.\n",
    "\n",
    "# generating random test sample\n",
    "\n",
    "x1 = torch.randn(123, 1, INPUT_DIM)\n",
    "x2 = torch.randn(12, 1, INPUT_DIM)\n",
    "x3 = torch.randn(13, 1, INPUT_DIM)\n",
    "x4 = torch.randn(23, 1, INPUT_DIM)\n",
    "y1 = torch.Tensor([[1]])\n",
    "y2 = torch.Tensor([[1]])\n",
    "y3 = torch.Tensor([[1]])\n",
    "y4 = torch.Tensor([[1]])\n",
    "X_train = [x1, x2, x3, x4]\n",
    "Y_train = [y1, y2, y3, y4]\n",
    "model = Model(kernel, X_train, Y_train).to(dev)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from svm.svm import SVM\n",
    "svm = SVM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training begin\n",
      "tensor([[-0.0242]], grad_fn=<MulBackward0>)\n",
      "Academic license - for non-commercial use only - expires 2022-10-26\n",
      "Using license file C:\\Users\\NHT\\gurobi.lic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\NHT\\Desktop\\统计学习\\proj\\sl2021\\svm\\svm.py:94: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  gram = np.array([[Y[i] * Y[j] * self.kernel(X[i], X[j]) for j in range(N)] for i in range(N)])\n",
      "D:\\NHT\\Desktop\\统计学习\\proj\\sl2021\\svm\\svm.py:94: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  gram = np.array([[Y[i] * Y[j] * self.kernel(X[i], X[j]) for j in range(N)] for i in range(N)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:87: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "D:\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:87: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "D:\\Anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:171: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0.]\n",
      "1.0\n",
      "tensor([[-0.]], grad_fn=<MulBackward0>)\n",
      "[0. 0. 0. 0.]\n",
      "1.0\n",
      "tensor([[-0.]], grad_fn=<MulBackward0>)\n",
      "[0. 0. 0. 0.]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# block 8, training.\n",
    "\n",
    "class myCustom(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, output):\n",
    "        return output\n",
    "    \n",
    "criterion = myCustom()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "print(\"training begin\")\n",
    "for rounds in range(1000):\n",
    "    for epoch in range(5):\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize kernel-svm objective wrt \\theta (kernel parameters)\n",
    "        output = model()\n",
    "        loss = criterion(output)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(loss)\n",
    "        \n",
    "        \n",
    "        # WARNING------------------------------------------this block needs to be modified----------\n",
    "        # call kernel-svm solver to optimize objective wrt alpha (at the same time, passing the current kernel)\n",
    "        # returns the updated new_alphas\n",
    "        new_alphas = svm.fit(X_train, \n",
    "                             Y_train,\n",
    "                             kernel=model.kernel_np)\n",
    "        print(new_alphas)\n",
    "        print(svm.score(X_train, Y_train))\n",
    "        # -------------------------------------------------------------\n",
    "        \n",
    "        model.update_alpha(torch.tensor(new_alphas))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
